<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
<img src="../images/csg4ed-small.png" alt="Enhancing Social Good in Computing"
<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home page</a>
  <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="risks.html">Risks</a>
	<li><a href="choices.html">Choices</a>
	<li><a href="ethics.html">Ethical Reflections</a>
	<li><a href="references.html">References</a>
   <li><a href="process.html">Process Support</a>
</ul>

<!-- Main content -->
<h1>Technology Choices</h1>


</ul><p>With the wide array of applications and potential for both positive and negative outcomes for society, there are also a multitude of choices to be made to ensure the best possible use of this technology. Starting with law enforcement usage of the technology, there are many unresolved choices and discussions that need to be had concerning the change in relationship between law enforcers and the general public caused by adopting this technology on a wide scale and usage in public areas. The justice system, just as any other human dependent system, has flaws that can take shape in many forms such as biases. Failure to take this idea into account when considering the implementation of this software can lead to misuse and abuse of this technology and enhances the flaws already present in the system. For instance, whilst it is true that facial recognition AI has come a long way since its conception, There are still inaccuracies in identifying people. In 2001 a test of IBM’s facial recognition technology when tested against people of colour was discovered to be accurate only 46% of the time. Now this is no fault of the creators making a racist program but due to some unconsidered consequences of the design, people with darker skin tones will reflect less light, and therefore provide less detail to the program and skew the result (Lunter, 2020). This can make already pre-existing flaws within the justice system more prominent. This is why it is important for us to make the necessary choices and open discussions about it. The core of this conversation would be around accountability (through increased transparency), regulation, audit and explanation of its usage on a case by case basis. This framework of ideas would not only benefit police enforcement but also teach other sectors of society a lesson on how they can frame the usage of the technology for themselves (Almeida et al., 2021). Only people in high roles should have the role to even consider the usage of this technology in public places and should be required to explain (if inquired) the cause for usage and as well as the degree to its usage, data stored and how the process was done from start to finish. If any irregularities are discovered there should also be appropriate apprehensive actions undertaken. Another choice that needs to be decided is the usage of this technology by private companies and if so under what conditions would it be acceptable to operate. How long should it store data, who has control of it and should it be allowed on public spaces rather than just on their premises. The addition of facial recognition into private business gives them more data to analyse their customers to a new level in terms of demographics and can possibly be used to detect the willingness of customers to pay for a particular good or service. For instance a recovering alcoholic after a period of time may have the stronger desire for health insurance, due to their history drinking leading to increased health risks. This can cause what is referred to as perfect price discrimination where buisness could maxmise their profit as they can more accurately determine the willingness of a customer to pay. This results in a decrease in consumer surplus. On top of this refusing service on the basis of sensitive information such as the aforementioned can be illegal as it may conflict with many anti-discrimination laws already in place (Carlson et al., 2019). There are many more choices besides these that need to be addressed if we ever want to implement this technology on a wide scale, in order for it to be used to its fullest capacity to reap the most benefits whilst also not infringing on the privacy rights afforded to citizens and fairness.<p>

<!-- Sign and date the page, it's only polite! -->
<address>Made 1 March 2021<br>
  by Tony Clear.</address>
 
<p><em>thanks to W3C for tutorial and adapted code from <a href="https://www.w3.org/Style/Examples/011/firstcss.en.html">Style Examples</a></p></em>
<p><em>also thanks to WDN for HTML and CSS resources and any adapted code snippets from <a href= "https://developer.mozilla.org/en-US/docs/Web">Mozilla Developer Network</a></p></em 
 </html>