<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>risks</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
    <img src="../images/csg4ed-small.png" alt="Enhancing Social Good in Computing"
    <!-- Site navigation menu -->

    <ul class="navbar">
        <li><a href="../index.html">Home page</a>
        <li><a href="topic.html">Technology/Topic</a>
        <li><a href="opportunities.html">Opportunities</a>
        <li><a href="misc/risks.html">Risks</a>
        <li><a href="choices.html">Choices</a>
        <li><a href="ethics.html">Ethical Reflections</a>
        <li><a href="references.html">References</a>
        <li><a href="process.html">Process Support</a>
    </ul>

    <!-- Main content -->
    <h1>Technology Risks</h1>


    </ul><h4><p>Risk 1<p></h4>
    <p>Although there are many benefits that come with the use of facial recognition, there are also many risks. Some of the risks that are present are related to the quality and accuracy of the facial recognition technology if it were to be used by law enforcement agencies, since the answer the software could give, could very well put someone in prison.  and a few of the risks involved are caused because the use of the technology itself would be an invasion of people's privacy rights, and even with the permission of the people the software could be exploited and used for the wrong things. If the Law enforcement started using facial recognition software in bodycams as they are patrolling the streets. Civilians won't have the right to choose whether or not they want to get recorded, because there are already plenty of places that use CCTV and some of those CCTV have some sort of facial recognition software working with it, in those cases there is usually a sign somewhere saying there is a CCTV camera operating and the person can decide whether or not they want to enter and be recorded, but with the body cams on the cops they will always be recording when the cop in on shift and if they are interacting with people the person being recorded doesnt get an option. (Bud, 2016). Another way the use of facial recognition in public areas could be a violation of privacy rights, is with the misuse of the technology itself. Because the people  this technology is being used on are putting their trust in the people who are using it to use it properly and fairly, however if this vast amount of information is used incorrectly it could lead to the repression of a whole population. A good example of such privacy issues being thrown out the window is in China where elected politicians are disregarding the privacy of their citizens and collecting information on them without their permission. (Leong, 2019). This sort of exploitation of delicate information cannot be trusted to be used honourably all the time and everytime, as there will be people who will try to exploit it for personal gain or misuse. Because each database for every single different type of facial recognition contains a lot of personal information on each person within the database, without any way to regulate the use of this technology properly there will always be a threat to people’s privacy rights.</p>

    <h4><p>Risk 2<p></h4>
    <p>
        The accuracy of the software that is being used is also another risk that needs to be discussed. If law enforcement starts using facial recognition software as credible evidence in court and the software ends up with false positives the wrong people could end up in jail for something they didn't do. A study conducted in 2018 by a researcher from MIT Joy Buolamwini shows that Images that contained people with darker skin created errors in the software, nearly 35% of the images which contained darker skinned females had errors arise while scanning, where as the photos with white men had a 99% chance of working perfectly without any errors. This problem arose because the database the software was checking from had more images of white men contained in it, this problem could cause a real risk in society. If there aren't enough samples from one demographic present in the database then there could be errors that arise and give the police false information. Border control and fairness issues at the border are also raised as a concern when talking about facial recognition technology usage, if the software contains too much of one demographic the software could also falsely flag someone at the airport for suspicious behaviour when they haven't done anything since all the software will have to learn off of is in contained in its database. Researchers from GeorgeTown Law School estimated that 117 million American adults are contained within databases for facial recognition software that is used by law enforcement, and african americans were mostly singled out because there is a disproportionate amount of mug-shots in the database. These inaccuracy’s need to be discussed and fixed early on, before facial recognition could be used as an everyday thing because these sorts of errors could lead to the AI’s that are being created to become “racist” to some extent and starting racial profiling people, if this occurs a lot of issues will arise which could lead to backlash from the public towards the government and people using the technology for legal purposes. Evidence that such technology could be considered as racist was given in 2015 when Google's image recognition app classified african americans as “gorillas” and they had to announce a public apology, this shows that such technology could become racist as further development occurs without these errors being fixed. (Lohr, 2018)
    </p>
    <!-- Sign and date the page, it's only polite! -->
    <address>
        Made 1 March 2021<br>
        by Tony Clear.
    </address>

    <p><em>thanks to W3C for tutorial and adapted code from <a href="https://www.w3.org/Style/Examples/011/firstcss.en.html">Style Examples</a></p></em>
    <p><em>also thanks to WDN for HTML and CSS resources and any adapted code snippets from <a href="https://developer.mozilla.org/en-US/docs/Web">Mozilla Developer Network</a></p></em>
</html>